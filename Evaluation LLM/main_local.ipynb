{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T14:26:20.335225Z",
     "start_time": "2025-04-27T14:26:12.923848Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import ollama\n",
    "import pandas as pd\n",
    "import evaluate\n",
    "from scipy.stats import ks_2samp\n",
    "from io import StringIO\n",
    "import json"
   ],
   "id": "7a9a2fc61c8b90c6",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Manuel\\Desktop\\Cosecose\\PR1\\TestBiometria\\venv\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Config",
   "id": "1060c2779d546ac6"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T14:26:20.833194Z",
     "start_time": "2025-04-27T14:26:20.585313Z"
    }
   },
   "cell_type": "code",
   "source": [
    "MODEL_NAME = \"qwen2.5:3b\"\n",
    "\n",
    "# Dataset di domande e risposte\n",
    "with open('qa_dataset.json', 'r', encoding='utf-8') as f:\n",
    "    qa_dataset = json.load(f)\n",
    "\n",
    "# Dati reali per confronto tabellare\n",
    "real_data = pd.read_excel(\"2022.11ÎË▒Ý▓╣│õÍð╬─Ê¹╩│/Shanghai_T1DM_Summary.xlsx\")"
   ],
   "id": "5df5b1433aeac589",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Funzioni per evaluation del qa",
   "id": "25f373ac5c9a4ec0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T14:26:20.879785Z",
     "start_time": "2025-04-27T14:26:20.866260Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def query_ollama(prompt):\n",
    "    \"\"\"Manda un prompt al modello Ollama e restituisce la risposta.\"\"\"\n",
    "    response = ollama.chat(\n",
    "        model=MODEL_NAME,\n",
    "        messages=[{\"role\": \"user\", \"content\": prompt}]\n",
    "    )\n",
    "    return response['message']['content']\n",
    "\n",
    "def evaluate_qa(predictions, references):\n",
    "    \"\"\"Valuta domande e risposte con BERTScore.\"\"\"\n",
    "    bertscore = evaluate.load(\"bertscore\")\n",
    "    results = bertscore.compute(predictions=predictions, references=references, lang=\"it\")\n",
    "    return results\n",
    "\n",
    "def run_qa_evaluation():\n",
    "    print(\"\\n=== Valutazione Risposte a Domande ===\")\n",
    "    predictions = []\n",
    "    references = []\n",
    "\n",
    "    for item in qa_dataset:\n",
    "        prompt = f\"Rispondi in modo conciso alla domanda: {item['question']}\"\n",
    "        response = query_ollama(prompt)\n",
    "        predictions.append(response.strip())\n",
    "        references.append(item['answer'])\n",
    "\n",
    "    results = evaluate_qa(predictions, references)\n",
    "    f1_scores = results['f1']\n",
    "    f1_medio = sum(f1_scores) / len(f1_scores)\n",
    "\n",
    "    print(\"\\nBERTScore medio (F1):\", round(f1_medio, 4))"
   ],
   "id": "cf6d68d9fa0251ac",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Funzioni per tabular evaluation (TDB)",
   "id": "c444f3bab7b984d8"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "from scipy.stats import ks_2samp\n",
    "from io import StringIO\n",
    "\n",
    "\n",
    "def fetch_synthetic_data(prompt):\n",
    "    \"\"\"Invia una query per ottenere i dati sintetici sotto forma di tabella.\"\"\"\n",
    "    response = query_ollama(prompt)\n",
    "    return response\n",
    "\n",
    "\n",
    "def extract_table_from_response(response):\n",
    "    \"\"\"Estrae la tabella da una risposta testuale.\"\"\"\n",
    "    match = re.search(r\"(\\|.*\\|)\", response, re.DOTALL)\n",
    "    if match:\n",
    "        return match.group(0)\n",
    "    return None\n",
    "\n",
    "\n",
    "def load_data_from_string(table_data):\n",
    "    \"\"\"Carica i dati da una stringa in un DataFrame Pandas.\"\"\"\n",
    "    df = pd.read_csv(StringIO(table_data), sep='|', engine='python', skipinitialspace=True)\n",
    "\n",
    "    # Rimuove la colonna \"Unnamed: 0\" che potrebbe essere stata generata\n",
    "    if 'Unnamed: 0' in df.columns:\n",
    "        df = df.drop(columns=['Unnamed: 0'])\n",
    "\n",
    "    # Normalizza i nomi delle colonne rimuovendo spazi extra e uniformando a minuscolo\n",
    "    df.columns = df.columns.str.strip().str.lower()\n",
    "    return df\n",
    "\n",
    "\n",
    "def ks_test_between_columns(real_column, synthetic_column):\n",
    "    \"\"\"Esegue il test di Kolmogorov-Smirnov tra due colonne.\"\"\"\n",
    "    try:\n",
    "        statistic, p_value = ks_2samp(real_column, synthetic_column)\n",
    "        return {\"KS-statistic\": statistic, \"p-value\": p_value}\n",
    "    except Exception as e:\n",
    "        return {\"error\": str(e)}\n",
    "\n",
    "\n",
    "def evaluate_synthetic_data(real_data, synthetic_data):\n",
    "    \"\"\"Valuta la qualità dei dati sintetici confrontandoli con i dati reali.\"\"\"\n",
    "    ks_results = {}\n",
    "    for column in real_data.columns:\n",
    "        # Controlla se la colonna esiste anche nei dati sintetici\n",
    "        if column in synthetic_data.columns:\n",
    "            ks_results[column] = ks_test_between_columns(real_data[column], synthetic_data[column])\n",
    "        else:\n",
    "            ks_results[column] = {\"error\": f\"Colonna '{column}' mancante nei dati sintetici.\"}\n",
    "    return ks_results\n",
    "\n",
    "\n",
    "def print_ks_results(ks_results):\n",
    "    \"\"\"Stampa i risultati del test KS per ogni colonna.\"\"\"\n",
    "    for column, result in ks_results.items():\n",
    "        if \"error\" in result:\n",
    "            print(f\"\\nColonna '{column}': Errore - {result['error']}\")\n",
    "        else:\n",
    "            print(f\"\\nColonna '{column}': KS-statistic={result['KS-statistic']:.4f}, p-value={result['p-value']:.4f}\")\n",
    "\n",
    "\n",
    "def run_tabular_evaluation(real_data):\n",
    "    print(\"\\n=== Generazione e Valutazione Dati Tabulari ===\")\n",
    "\n",
    "    prompt = \"\"\"\n",
    "    Genera una tabella con le seguenti indicazioni, prima dei : avrai l'header della colonna e dopo avrai che tipo di valore mettere all'interno della cella.\n",
    "\n",
    "    La tabella deve contenere circa 20 righe di dati realistici che siano *simili* ai seguenti valori (ma *non identici*):\n",
    "    - Patient Number: numeri sequenziali univoci.\n",
    "    - High-Density Lipoprotein Cholesterol: valori tipici tra 0.70 e 2.50 mmol/L.\n",
    "    - Gender: 1 (Femmina) o 2 (Maschio).\n",
    "    - Low-Density Lipoprotein Cholesterol: valori tra 1.50 e 4.50 mmol/L.\n",
    "    - Age: età in anni, tipicamente tra 30 e 80.\n",
    "    - Creatinine: livelli tra 40 e 120 umol/L.\n",
    "    - Height: valori tra 1.50 e 1.90 m.\n",
    "    - Estimated Glomerular Filtration Rate: valori tra 50 e 160 ml/min/1.73m2.\n",
    "    - Weight: tra 50 e 90 kg.\n",
    "    - Uric Acid: valori tra 150 e 420 mmol/L.\n",
    "    - BMI: calcolato in kg/m2, tra 18.5 e 30.\n",
    "    - Blood Urea Nitrogen: livelli tra 2.5 e 7.0 mmol/L.\n",
    "    - Smoking History: anni o pacchetti di storia da 0 a 50.\n",
    "    - Hypoglycemia: “yes” o “no”.\n",
    "    - Alcohol Drinking History: “drinker” o “non-drinker”.\n",
    "    - Type of Diabetes: tipicamente \"T1DM\" (Type 1 Diabetes Mellitus).\n",
    "    - Duration of Diabetes: durata in anni, tra 0 e 30.\n",
    "    - Acute Diabetic Complications: descrizioni brevi o \"none\".\n",
    "    - Diabetic Macrovascular/Microvascular Complications: brevi elenchi o \"none\".\n",
    "    - Comorbidities: elenchi brevi o \"none\".\n",
    "    - Hypoglycemic Agents/Other Agents: descrizioni brevi di farmaci.\n",
    "    - Parametri di glucosio, insulina e colesterolo: valori tipici coerenti con i livelli realistici.\n",
    "\n",
    "    Genera ogni riga con dati casuali ma realistici, mantenendo coerenza tra i valori correlati (ad esempio, BMI deve essere congruente con altezza e peso). Se non hai bisogno di dettagli per alcune colonne, puoi inserire “/” o lasciare il campo vuoto.\n",
    "\n",
    "    RISPONDI SOLO CON LA TABELLA. NON SCRIVERE ALTRO.\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        # Ottieni i dati sintetici\n",
    "        response = fetch_synthetic_data(prompt)\n",
    "\n",
    "        # Estrai la tabella\n",
    "        table_data = extract_table_from_response(response)\n",
    "        if not table_data:\n",
    "            raise ValueError(\"Nessuna tabella trovata nella risposta.\")\n",
    "\n",
    "        # Carica i dati sintetici in un DataFrame\n",
    "        synthetic_data = load_data_from_string(table_data)\n",
    "\n",
    "        print(\"Tabella sintetica:\\n\", synthetic_data)\n",
    "\n",
    "        # Valuta la qualità dei dati sintetici confrontandoli con quelli reali\n",
    "        ks_results = evaluate_synthetic_data(real_data, synthetic_data)\n",
    "\n",
    "        # Stampa i risultati\n",
    "        print_ks_results(ks_results)\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Errore: {e}\")\n"
   ],
   "id": "5a1d9153eaab58a3",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-04-27T14:28:55.058423Z",
     "start_time": "2025-04-27T14:26:23.391684Z"
    }
   },
   "cell_type": "code",
   "source": "run_qa_evaluation()",
   "id": "b7ca234a14e8df2f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Valutazione Risposte a Domande ===\n",
      "\n",
      "BERTScore medio (F1): 0.7301\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "run_tabular_evaluation(real_data)",
   "id": "f5ab13351e2d5502",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "",
   "id": "5ce1726dc32713",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
