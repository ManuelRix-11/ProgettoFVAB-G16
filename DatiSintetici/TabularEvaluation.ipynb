{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Tabular Evaluation",
   "id": "3665e7a8eb23f17b"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T22:09:25.977618Z",
     "start_time": "2025-05-15T22:09:25.842349Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Caricamento dei dataset\n",
    "original_data = pd.read_csv('./TabularData/diabetic_data_filtered_250.csv')\n",
    "synthetic_data = pd.read_csv('TabularData/ClassicPrompt/Mistral_synthetic_diabetic_data.csv')"
   ],
   "id": "406c4adeab002933",
   "outputs": [],
   "execution_count": 48
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 1. Pulizia delle colonne non rilevanti",
   "id": "cdd4df8e4b14baa1"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T22:09:28.913951Z",
     "start_time": "2025-05-15T22:09:28.887330Z"
    }
   },
   "cell_type": "code",
   "source": [
    "original_data = original_data.drop([\"encounter_id\", \"patient_nbr\"], axis=1)\n",
    "if \"encounter_id\" in synthetic_data.columns or \"patient_nbr\" in synthetic_data.columns:\n",
    "    synthetic_data = synthetic_data.drop([\"encounter_id\", \"patient_nbr\"], axis=1)"
   ],
   "id": "32da2d834fa6374a",
   "outputs": [],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 2. Funzioni di Similarità per Diversi Tipi di Dati",
   "id": "df4c405ad0a2f4a"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.1 Similarità con Differenze Assolute e Distanza Euclidea Normalizzata",
   "id": "49079a665be212a0"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T22:09:44.844640Z",
     "start_time": "2025-05-15T22:09:44.785712Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_numerical_similarity(series1, series2):\n",
    "    \"\"\"Calcola la similarità per variabili numeriche usando statistiche descrittive normalizzate\"\"\"\n",
    "    stats1 = series1.describe()\n",
    "    stats2 = series2.describe()\n",
    "\n",
    "    # Confronto di media, std e percentili\n",
    "    diff_mean = abs(stats1['mean'] - stats2['mean']) / max(abs(stats1['mean']), 1)\n",
    "    diff_std = abs(stats1['std'] - stats2['std']) / max(abs(stats1['std']), 1)\n",
    "\n",
    "    # Similarità come 1 - media delle differenze normalizzate\n",
    "    similarity = 1 - np.mean([diff_mean, diff_std])\n",
    "    return similarity\n",
    "\n",
    "def calculate_categorical_similarity(series1, series2):\n",
    "    \"\"\"Calcola la similarità per variabili categoriche usando distribuzione delle frequenze\"\"\"\n",
    "    # Calcolo delle frequenze relative\n",
    "    freq1 = series1.value_counts(normalize=True)\n",
    "    freq2 = series2.value_counts(normalize=True)\n",
    "\n",
    "    # Unione di tutte le categorie\n",
    "    all_categories = set(freq1.index) | set(freq2.index)\n",
    "\n",
    "    # Normalizzazione delle frequenze\n",
    "    freq1 = freq1.reindex(all_categories).fillna(0)\n",
    "    freq2 = freq2.reindex(all_categories).fillna(0)\n",
    "\n",
    "    # Calcolo della similarità usando la distanza di Jensen-Shannon\n",
    "    similarity = 1 - np.sqrt(np.mean((freq1 - freq2) ** 2))\n",
    "    return similarity\n",
    "\n",
    "def calculate_overall_similarity(df1, df2):\n",
    "    \"\"\"Calcola la similarità complessiva tra i due dataset\"\"\"\n",
    "    similarities = {}\n",
    "\n",
    "    for column in df1.columns:\n",
    "        if column in df2.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df1[column]):\n",
    "                similarity = calculate_numerical_similarity(df1[column], df2[column])\n",
    "                similarities[column] = {'type': 'numerical', 'similarity': similarity}\n",
    "            else:\n",
    "                similarity = calculate_categorical_similarity(df1[column], df2[column])\n",
    "                similarities[column] = {'type': 'categorical', 'similarity': similarity}\n",
    "\n",
    "    # Crea DataFrame dei risultati\n",
    "    results = pd.DataFrame.from_dict(similarities, orient='index')\n",
    "\n",
    "    # Calcola similarità media complessiva\n",
    "    overall_similarity = results['similarity'].mean()\n",
    "\n",
    "    return results, overall_similarity\n",
    "\n",
    "# Calcola e visualizza i risultati\n",
    "similarity_results, overall = calculate_overall_similarity(original_data, synthetic_data)\n",
    "print(f\"\\nSimilarità complessiva tra i dataset: {overall:.2%}\")\n",
    "print(\"\\nSimilarità per feature:\")\n",
    "print(similarity_results.sort_values('similarity', ascending=False))"
   ],
   "id": "f2dc5cd5068dc88",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'similarity'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[51], line 53\u001B[0m\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results, overall_similarity\n\u001B[0;32m     52\u001B[0m \u001B[38;5;66;03m# Calcola e visualizza i risultati\u001B[39;00m\n\u001B[1;32m---> 53\u001B[0m similarity_results, overall \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_overall_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msynthetic_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     54\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mSimilarità complessiva tra i dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moverall\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2%\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     55\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mSimilarità per feature:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[51], line 48\u001B[0m, in \u001B[0;36mcalculate_overall_similarity\u001B[1;34m(df1, df2)\u001B[0m\n\u001B[0;32m     45\u001B[0m results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(similarities, orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     47\u001B[0m \u001B[38;5;66;03m# Calcola similarità media complessiva\u001B[39;00m\n\u001B[1;32m---> 48\u001B[0m overall_similarity \u001B[38;5;241m=\u001B[39m \u001B[43mresults\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msimilarity\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m     50\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results, overall_similarity\n",
      "File \u001B[1;32m~\\Desktop\\Cosecose\\Magistrale\\FVAB\\ProgettoFVAB-G16\\Evaluation LLM\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Desktop\\Cosecose\\Magistrale\\FVAB\\ProgettoFVAB-G16\\Evaluation LLM\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    415\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[1;32m--> 417\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'similarity'"
     ]
    }
   ],
   "execution_count": 51
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### 2.2 Similarità con KS-statistic e Jensen-Shannon",
   "id": "8a555aac6a4a88a3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T22:09:49.153827Z",
     "start_time": "2025-05-15T22:09:49.095560Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from scipy.stats import ks_2samp\n",
    "from scipy.stats import entropy\n",
    "\n",
    "def calculate_numerical_similarity_ks(series1, series2):\n",
    "    \"\"\"\n",
    "    Calcola la similarità per variabili numeriche usando il test KS.\n",
    "    Restituisce 1 - statistica KS per avere una misura di similarità invece che di distanza\n",
    "    \"\"\"\n",
    "    # Rimuove i valori NaN\n",
    "    s1 = series1.dropna()\n",
    "    s2 = series2.dropna()\n",
    "\n",
    "    # Calcola la KS statistic\n",
    "    ks_statistic, _ = ks_2samp(s1, s2)\n",
    "\n",
    "    # Converte la distanza in similarità\n",
    "    similarity = 1 - ks_statistic\n",
    "    return similarity\n",
    "\n",
    "def calculate_categorical_similarity_js(series1, series2):\n",
    "    \"\"\"\n",
    "    Calcola la similarità per variabili categoriche usando Jensen-Shannon divergence\n",
    "    \"\"\"\n",
    "    # Calcolo delle frequenze relative\n",
    "    freq1 = series1.value_counts(normalize=True)\n",
    "    freq2 = series2.value_counts(normalize=True)\n",
    "\n",
    "    # Unione di tutte le categorie\n",
    "    all_categories = sorted(set(freq1.index) | set(freq2.index))\n",
    "\n",
    "    # Normalizzazione delle frequenze con zero-padding\n",
    "    p = np.array([freq1.get(cat, 0) for cat in all_categories])\n",
    "    q = np.array([freq2.get(cat, 0) for cat in all_categories])\n",
    "\n",
    "    # Calcolo della distribuzione media\n",
    "    m = 0.5 * (p + q)\n",
    "\n",
    "    # Calcolo della Jensen-Shannon divergence\n",
    "    # Aggiungiamo un epsilon per evitare log(0)\n",
    "    eps = 1e-10\n",
    "    js_divergence = 0.5 * (\n",
    "        entropy(p + eps, m + eps) +\n",
    "        entropy(q + eps, m + eps)\n",
    "    )\n",
    "\n",
    "    # Convertiamo la divergenza in similarità\n",
    "    # La JS divergence è limitata a [0, log(2)], quindi normalizziamo\n",
    "    similarity = 1 - (js_divergence / np.log(2))\n",
    "    return similarity\n",
    "\n",
    "def calculate_overall_similarity(df1, df2):\n",
    "    \"\"\"Calcola la similarità complessiva tra i due dataset\"\"\"\n",
    "    similarities = {}\n",
    "\n",
    "    for column in df1.columns:\n",
    "        if column in df2.columns:\n",
    "            if pd.api.types.is_numeric_dtype(df1[column]):\n",
    "                similarity = calculate_numerical_similarity_ks(df1[column], df2[column])\n",
    "                similarities[column] = {'type': 'numerical (KS)', 'similarity': similarity}\n",
    "            else:\n",
    "                similarity = calculate_categorical_similarity_js(df1[column], df2[column])\n",
    "                similarities[column] = {'type': 'categorical (JS)', 'similarity': similarity}\n",
    "\n",
    "    # Crea DataFrame dei risultati\n",
    "    results = pd.DataFrame.from_dict(similarities, orient='index')\n",
    "\n",
    "    # Calcola similarità media complessiva\n",
    "    overall_similarity = results['similarity'].mean()\n",
    "\n",
    "    return results, overall_similarity\n",
    "\n",
    "similarity_results, overall = calculate_overall_similarity(original_data, synthetic_data)\n",
    "print(f\"\\nSimilarità complessiva tra i dataset: {overall:.2%}\")\n",
    "print(\"\\nSimilarità per feature:\")\n",
    "print(similarity_results.sort_values('similarity', ascending=False))\n"
   ],
   "id": "543dffd404c59eaa",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'similarity'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[52], line 72\u001B[0m\n\u001B[0;32m     68\u001B[0m     overall_similarity \u001B[38;5;241m=\u001B[39m results[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msimilarity\u001B[39m\u001B[38;5;124m'\u001B[39m]\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m     70\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m results, overall_similarity\n\u001B[1;32m---> 72\u001B[0m similarity_results, overall \u001B[38;5;241m=\u001B[39m \u001B[43mcalculate_overall_similarity\u001B[49m\u001B[43m(\u001B[49m\u001B[43moriginal_data\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43msynthetic_data\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     73\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mSimilarità complessiva tra i dataset: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00moverall\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.2%\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     74\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124mSimilarità per feature:\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "Cell \u001B[1;32mIn[52], line 68\u001B[0m, in \u001B[0;36mcalculate_overall_similarity\u001B[1;34m(df1, df2)\u001B[0m\n\u001B[0;32m     65\u001B[0m results \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame\u001B[38;5;241m.\u001B[39mfrom_dict(similarities, orient\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mindex\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     67\u001B[0m \u001B[38;5;66;03m# Calcola similarità media complessiva\u001B[39;00m\n\u001B[1;32m---> 68\u001B[0m overall_similarity \u001B[38;5;241m=\u001B[39m \u001B[43mresults\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43msimilarity\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m]\u001B[49m\u001B[38;5;241m.\u001B[39mmean()\n\u001B[0;32m     70\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m results, overall_similarity\n",
      "File \u001B[1;32m~\\Desktop\\Cosecose\\Magistrale\\FVAB\\ProgettoFVAB-G16\\Evaluation LLM\\venv\\lib\\site-packages\\pandas\\core\\frame.py:4102\u001B[0m, in \u001B[0;36mDataFrame.__getitem__\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m   4100\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcolumns\u001B[38;5;241m.\u001B[39mnlevels \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[0;32m   4101\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_getitem_multilevel(key)\n\u001B[1;32m-> 4102\u001B[0m indexer \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcolumns\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_loc\u001B[49m\u001B[43m(\u001B[49m\u001B[43mkey\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   4103\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m is_integer(indexer):\n\u001B[0;32m   4104\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m [indexer]\n",
      "File \u001B[1;32m~\\Desktop\\Cosecose\\Magistrale\\FVAB\\ProgettoFVAB-G16\\Evaluation LLM\\venv\\lib\\site-packages\\pandas\\core\\indexes\\range.py:417\u001B[0m, in \u001B[0;36mRangeIndex.get_loc\u001B[1;34m(self, key)\u001B[0m\n\u001B[0;32m    415\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key) \u001B[38;5;28;01mfrom\u001B[39;00m\u001B[38;5;250m \u001B[39m\u001B[38;5;21;01merr\u001B[39;00m\n\u001B[0;32m    416\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(key, Hashable):\n\u001B[1;32m--> 417\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n\u001B[0;32m    418\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_indexing_error(key)\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(key)\n",
      "\u001B[1;31mKeyError\u001B[0m: 'similarity'"
     ]
    }
   ],
   "execution_count": 52
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## 3. Visualizzazione delle Distribuzioni",
   "id": "b3b41dafd01be7e7"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-05-15T22:13:11.906014Z",
     "start_time": "2025-05-15T22:13:11.895997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def plot_feature_distributions(df1, df2, column):\n",
    "    \"\"\"Visualizza le distribuzioni di una feature nei due dataset\"\"\"\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    if pd.api.types.is_numeric_dtype(df1[column]):\n",
    "        # Per variabili numeriche: plot delle distribuzioni\n",
    "        sns.kdeplot(data=df1, x=column, label='Original', alpha=0.5)\n",
    "        sns.kdeplot(data=df2, x=column, label='Synthetic', alpha=0.5)\n",
    "        plt.title(f'Distribution Comparison - {column}')\n",
    "    else:\n",
    "        # Per variabili categoriche: plot delle frequenze relative\n",
    "        freq1 = df1[column].value_counts(normalize=True)\n",
    "        freq2 = df2[column].value_counts(normalize=True)\n",
    "\n",
    "        # Combina le categorie\n",
    "        categories = sorted(set(freq1.index) | set(freq2.index))\n",
    "\n",
    "        x = np.arange(len(categories))\n",
    "        width = 0.35\n",
    "\n",
    "        plt.bar(x - width/2, [freq1.get(cat, 0) for cat in categories], width, label='Original')\n",
    "        plt.bar(x + width/2, [freq2.get(cat, 0) for cat in categories], width, label='Synthetic')\n",
    "        plt.xticks(x, categories, rotation=45)\n",
    "        plt.title(f'Category Frequencies - {column}')\n",
    "\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "columns_to_plot = ['race', 'gender', 'age', 'max_glu_serum', 'A1Cresult', 'diabetesMed']\n",
    "\n",
    "for column in columns_to_plot:\n",
    "    if column.lower() in original_data.columns and column.lower() in synthetic_data.columns:\n",
    "        plot_feature_distributions(original_data, synthetic_data, column)\n",
    "    else:\n",
    "        print(f\"Attenzione: la colonna {column} non è presente in entrambi i dataset\")"
   ],
   "id": "88b8510c5dfb4f5d",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attenzione: la colonna race non è presente in entrambi i dataset\n",
      "Attenzione: la colonna gender non è presente in entrambi i dataset\n",
      "Attenzione: la colonna age non è presente in entrambi i dataset\n",
      "Attenzione: la colonna max_glu_serum non è presente in entrambi i dataset\n",
      "Attenzione: la colonna A1Cresult non è presente in entrambi i dataset\n",
      "Attenzione: la colonna diabetesMed non è presente in entrambi i dataset\n"
     ]
    }
   ],
   "execution_count": 56
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "c44d6d0946422222"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
